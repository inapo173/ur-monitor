import requests
from bs4 import BeautifulSoup
import os
import time
import re
import datetime
import random
import sys

# ==========================================
# 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚¨ãƒªã‚¢
# ==========================================

# ç›£è¦–ã—ãŸã„ç‰©ä»¶ã®URLãƒªã‚¹ãƒˆ
# â˜…ã“ã“ã«ã¯ã€Œæ™®é€šã®URLã€ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
# ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè‡ªå‹•ã§ãƒ‡ãƒ¼ã‚¿ã®ã‚ã‚‹ãƒšãƒ¼ã‚¸(_room.html)ã‚’æ¢ã—ã«è¡Œãã¾ã™ã€‚
TARGET_URLS = [
    # ç¦ä½ä¸€ä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2660.html",
    # æœ¨å ´å…¬åœ’ä¸‰å¥½ä½å®…
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_3450.html",
    # æœ¨å ´å…¬åœ’å¹³é‡ä½å®…
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_3570.html",
    # æœ¨å ´ä¸‰ä¸ç›®ãƒ‘ãƒ¼ã‚¯ãƒã‚¤ãƒ„
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_3860.html",
    # å¤§å³¶å…­ä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_1920.html",
    # é«˜å³¶å¹³å›£åœ°
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2250.html",
    # ã‚³ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«å’Œå…‰è¥¿å¤§å’Œ
    "https://www.ur-net.go.jp/chintai/kanto/saitama/50_4120.html",
    # å¿—æ‘ä¸€ä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_1190.html",
    # å¤§äº•å…­ä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_1830.html",
    # å—åƒä½ä¸ƒä¸ç›®ãƒã‚¤ãƒ„
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_4290.html",
    # ä¸Šé¦¬äºŒä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2400.html",
    # å°å³¶ç”ºäºŒä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2540.html",
    # æ±å››ãƒ„æœ¨äºŒä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2640.html",
    # å¤§è°·ç”°ä¸€ä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2810.html",
    # åŒ—ç ‚äº”ä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2820.html",
    # åŒ—ç ‚ä¸ƒä¸ç›®
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_2940.html",
    # ç¥ç”°å°å·ç”ºãƒã‚¤ãƒ„
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_3820.html",
    # æ–°è“®æ ¹
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_4760.html",
    # ã‚¢ã‚¯ã‚·ã‚¹æ±å››ãƒ„æœ¨
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_5840.html",
    # è‘›è¥¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¿ã‚¦ãƒ³æ¸…æ–°ãƒ—ãƒ©ã‚¶
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_3480.html",
    # å·å£èŠåœ’å›£åœ°
    "https://www.ur-net.go.jp/chintai/kanto/saitama/50_1820.html",
    # ã‚¢ãƒ¼ãƒãƒ³ãƒ©ã‚¤ãƒ•è¥¿æ–°äº•
    "https://www.ur-net.go.jp/chintai/kanto/tokyo/20_5320.html",
    
    # === ãƒ†ã‚¹ãƒˆç”¨ç‰©ä»¶ ===
    "https://www.ur-net.go.jp/chintai/kanto/saitama/50_1270.html"
]

# â˜…â˜…â˜… ãƒ†ã‚¹ãƒˆç”¨ï¼ˆ30ä¸‡å††ï¼‰ â˜…â˜…â˜… é€šçŸ¥ãŒæ¥ãŸã‚‰ 85000 ã«æˆ»ã—ã¦ãã ã•ã„
MAX_RENT_LIMIT = 300000

# GitHub Secretsã‹ã‚‰èª­ã¿è¾¼ã‚€
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
HEALTHCHECK_URL = os.environ.get("HEALTHCHECK_URL", "")

# ==========================================
# 2. ã‚·ã‚¹ãƒ†ãƒ é–¢æ•°ç¾¤
# ==========================================

def send_discord(message):
    if not DISCORD_WEBHOOK_URL:
        print("âš  ã€é‡è¦ã€‘Discord URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    try:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": message})
        print(">> Discordé€šçŸ¥é€ä¿¡å®Œäº†")
    except Exception as e:
        print(f"é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

def get_room_url(url):
    """
    æ™®é€šã®URL(.html)ã‚’ã€ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹URL(_room.html)ã«å¤‰æ›ã™ã‚‹
    """
    if "_room.html" in url:
        return url
    return url.replace(".html", "_room.html")

def extract_room_details(soup):
    rooms = []
    
    # ã€é‡è¦ã€‘æä¾›ã•ã‚ŒãŸHTMLè§£æã®çµæœã€
    # éƒ¨å±‹ãƒªã‚¹ãƒˆã¯å¿…ãš <tbody class="rep_room"> ã®ä¸­ã«ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚
    # é€†ã«ã€ã“ã“ä»¥å¤–ã«ã‚ã‚‹ã€Œå††ã€ã¯ãŸã ã®ç›®å®‰ï¼ˆç´¹ä»‹æ–‡ï¼‰ãªã®ã§ç„¡è¦–ã—ã¾ã™ã€‚
    
    table_body = soup.find("tbody", class_="rep_room")
    
    if not table_body:
        # _room.htmlã‚’è¦‹ã«è¡Œã£ã¦ã‚‚ã“ã“ãŒç©ºãªã‚‰ã€æœ¬å½“ã«ç©ºå®¤ãŒãªã„
        return []

    # éƒ¨å±‹ãƒªã‚¹ãƒˆã®å„è¡Œï¼ˆtrï¼‰ã‚’å–å¾—
    rows = table_body.find_all("tr")
    
    for row in rows:
        text = row.get_text()
        clean_text = re.sub(r'\s+', ' ', text).strip()
        
        # å®¶è³ƒã‚’æŠ½å‡º
        rent_match = re.search(r'([0-9,]+)\s?å††', clean_text)
        
        if rent_match:
            # ã‚«ãƒ³ãƒã‚’é™¤å»ã—ã¦æ•°å€¤åŒ–
            rent_str = rent_match.group(1).replace(",", "")
            try:
                rent = int(rent_str)
            except:
                continue
            
            # å®¶è³ƒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if rent > MAX_RENT_LIMIT:
                continue
            
            # ãã®ä»–ã®æƒ…å ±ã‚’æŠ½å‡º
            # éƒ¨å±‹ç•ªå·ï¼ˆä¾‹ï¼š1-35å·æ£Ÿ405å·å®¤ï¼‰
            room_num_match = re.search(r'([0-9\-]+å·æ£Ÿ[0-9]+å·å®¤|[0-9]+å·å®¤)', clean_text)
            room_number = room_num_match.group(1) if room_num_match else "éƒ¨å±‹ç•ªå·ä¸æ˜"
            
            # åºƒã•
            size_match = re.search(r'([0-9]+)\s?(ã¡|m2)', clean_text)
            
            # éšæ•°
            floor_match = re.search(r'([0-9]+)\s?éš', clean_text)
            
            # ã‚¿ã‚¤ãƒ—ï¼ˆ1LDKãªã©ï¼‰
            type_match = re.search(r'[0-9]?[LDKSR]+', clean_text)

            room_info = {
                "number": room_number,
                "rent_fmt": rent_match.group(0),
                "size": size_match.group(0) if size_match else "-",
                "floor": floor_match.group(0) if floor_match else "-",
                "type": type_match.group(0) if type_match else "-"
            }
            rooms.append(room_info)

    return rooms

def check_vacancy(original_url):
    # ã€é‡è¦ã€‘ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹ "_room.html" ã«å¤‰æ›ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹
    target_url = get_room_url(original_url)
    
    # ãƒ–ãƒ©ã‚¦ã‚¶ã®ãµã‚Šã‚’ã™ã‚‹ï¼ˆã“ã‚ŒãŒãªã„ã¨ _room.html ãŒã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹ï¼‰
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ]
    headers = {
        "User-Agent": random.choice(user_agents),
        "Referer": original_url  # å…ƒã®ãƒšãƒ¼ã‚¸ã‹ã‚‰æ¥ãŸãµã‚Šã‚’ã™ã‚‹
    }
    
    try:
        response = requests.get(target_url, headers=headers, timeout=30)
        
        # æ–‡å­—åŒ–ã‘å¯¾ç­–
        if response.encoding is None or response.encoding == 'ISO-8859-1':
            response.encoding = response.apparent_encoding

        # 404ã‚¨ãƒ©ãƒ¼ï¼ˆãƒšãƒ¼ã‚¸ãªã—ï¼‰ã¯ã€URã®å ´åˆã€Œéƒ¨å±‹ãŒã‚¼ãƒ­ã§ãƒšãƒ¼ã‚¸ãŒæ¶ˆã•ã‚ŒãŸã€å¯èƒ½æ€§ãŒé«˜ã„
        if response.status_code == 404:
            print(f"â†’ ç©ºããªã— (ãƒšãƒ¼ã‚¸æ¶ˆå¤±/404): {target_url}")
            return False
            
        if response.status_code != 200:
            print(f"âš  ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ ({response.status_code}): {target_url}")
            return False

        soup = BeautifulSoup(response.content, "html.parser")
        page_text = soup.get_text()

        # æº€å®¤ãƒ»çµ‚äº†ã®åˆ¤å®š
        if "æ²è¼‰ã¯çµ‚äº†ã„ãŸã—ã¾ã—ãŸ" in page_text or "ãŠæ¢ã—ã®ãƒšãƒ¼ã‚¸ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in page_text:
            print(f"â†’ æº€å®¤ (æ²è¼‰çµ‚äº†ç”»é¢): {target_url}")
            return False

        if "æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ç‰©ä»¶ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in page_text or "ç¾åœ¨ã€ç©ºãå®¤ã¯ã‚ã‚Šã¾ã›ã‚“" in page_text:
            print(f"â†’ ç©ºããªã—: {target_url}")
            return False

        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        rooms = extract_room_details(soup)
        
        if not rooms:
            print(f"â†’ æ¡ä»¶ã«åˆã†ç©ºãéƒ¨å±‹ãªã—ï¼ˆã¾ãŸã¯äºˆç®—ã‚ªãƒ¼ãƒãƒ¼ï¼‰: {target_url}")
            return False

        # é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
        title = soup.find("h1")
        area_name = title.get_text(strip=True) if title else "ä¸æ˜ãªå›£åœ°"
        
        msg = f"**ã€URç©ºå®¤ç™ºè¦‹ï¼ã€‘**\nTarget: {area_name}\nURL: {target_url}\n\n"
        for i, room in enumerate(rooms):
            if i >= 5:
                msg += "ã»ã‹è¤‡æ•°ä»¶ã‚ã‚Š...\n"
                break
            msg += f"ãƒ»{room['number']} | {room['type']} | {room['floor']} | **{room['rent_fmt']}**\n"
        
        send_discord(msg)
        return True

    except Exception as e:
        print(f"ä¾‹å¤–ç™ºç”Ÿ ({target_url}): {e}")
        return False

# ==========================================
# 3. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯
# ==========================================
if __name__ == "__main__":
    print("--- ç›£è¦–ã‚¸ãƒ§ãƒ–é–‹å§‹ ---")
    
    if DISCORD_WEBHOOK_URL:
        print("âœ… Discordè¨­å®š: OK")
    else:
        print("âŒ Discordè¨­å®š: æœªè¨­å®š")

    wait_time = random.randint(5, 15)
    print(f"Wait for {wait_time} sec...")
    time.sleep(wait_time)
    
    found_any_in_this_run = False
    
    for url in TARGET_URLS:
        if not url: continue
        is_found = check_vacancy(url)
        if is_found:
            found_any_in_this_run = True
        time.sleep(2)

    now_utc = datetime.datetime.now(datetime.timezone.utc)
    if now_utc.hour == 14 and now_utc.minute >= 25:
        if not found_any_in_this_run:
            summary_msg = "ğŸ **ã€æœ¬æ—¥ã®ç›£è¦–çµ‚äº†ã€‘**\n23:30ã®å®šæ™‚é€£çµ¡ã§ã™ã€‚\næœ¬æ—¥ã¯æ¡ä»¶ã«åˆã†ç©ºãç‰©ä»¶ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\nã¾ãŸæ˜æ—¥8:00ã‹ã‚‰ç›£è¦–ã‚’å†é–‹ã—ã¾ã™ã€‚"
            send_discord(summary_msg)

    if HEALTHCHECK_URL:
        try:
            requests.get(HEALTHCHECK_URL, timeout=10)
            print("Healthchecks Pingé€ä¿¡å®Œäº†")
        except:
            pass
            
    print("--- ç›£è¦–ã‚¸ãƒ§ãƒ–çµ‚äº† ---")
